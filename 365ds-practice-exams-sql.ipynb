{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/isissantoscosta/365ds-practice-exams-sql?scriptVersionId=241107439\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"9322a51f","metadata":{"papermill":{"duration":0.004192,"end_time":"2025-05-21T22:24:58.706425","exception":false,"start_time":"2025-05-21T22:24:58.702233","status":"completed"},"tags":[]},"source":["<a id='top'></a>\n","Created on May 21, 2025 ‚Ä¢ by [√çsis Santos Costa](https://www.linkedin.com/in/isis-santos-costa/)\n","\n","<hr>\n","\n","**How to expand and assess SQL skills?**\n","\n","This notebook focuses on solving questions from the [**365 Data Science ‚Ä¢ Practice Exams: SQL**](https://learn.365datascience.com/exams/?tab=practice) curriculum, a **free resource** designed to help test and elevate data science skills. Here, you'll find a set of practices on SQL querying and data analysis within a People Analytics context. It applies the steps of a business analysis process to get insights from the provided data, covering detailed answers to 365DS SQL Practice Exams 1, 2, and 3, with special emphasis on illustrating the usage and value of **SQL procedures and functions**.\n","\n","From the [365 Data Science Practice Exams](https://365datascience.com/resources-center/practice-exams/) webpage:\n","\n","> Discover a plethora of online exams that will test your current knowledge and ability to solve data science problems.  \n","> Evaluate your skills online **at no cost** with SQL mock tests, Excel and NumPy exam questions, and more.\n","\n","<br>\n","\n","The data for the 365 Data Science SQL Practice Exams is available as a Kaggle dataset: [üéì 365DS Practice Exams ‚Ä¢ People Analytics Dataset](https://www.kaggle.com/datasets/isissantoscosta/365ds-practice-exams-people-analytics-dataset/)."]},{"cell_type":"markdown","id":"913708eb","metadata":{"papermill":{"duration":0.003043,"end_time":"2025-05-21T22:24:58.713342","exception":false,"start_time":"2025-05-21T22:24:58.710299","status":"completed"},"tags":[]},"source":["<center>\n","    <img src='https://raw.githubusercontent.com/isis-santos-costa/isis-santos-costa/refs/heads/main/img/SQL.png' alt='databases' width='350'>\n","</center>"]},{"cell_type":"markdown","id":"84d2a6a6","metadata":{"papermill":{"duration":0.002989,"end_time":"2025-05-21T22:24:58.719654","exception":false,"start_time":"2025-05-21T22:24:58.716665","status":"completed"},"tags":[]},"source":["<a id='business_questions'></a>\n","\n","# <div style=\"background-color:#03002e; padding:18px; border-radius:8px; color:white; text-align:center; font-weight:regular; overflow:hidden\"><strong>Step 1 ‚Ä¢ Business questions</strong></div>\n","\n","In the realm of business, data is abundant, insights are precious. The distinction often lies in one crucial factor: **starting with the right business questions**. It transforms data analysis from a technical exercise into a **strategic driver**, focusing efforts on what truly matters. This ensures insights are actionable and directly align with **strategic goals**, such as increasing customer satisfaction, optimizing costs, and boosting revenue.\n","\n","For that reason, given the context defined by the exercise dataset - **People Analytics** - a first step to make the analysis interesting is to compile a set of strategic questions on that context that have the potential to drive impactful positive change **for the company's advancement**.\n","\n","With that in mind, here it goes a set of possible business questions to drive the analysis, categorized by People Analytics themes:\n","\n","**A. Workforce Demographics & Structure:**\n","\n","1. What is the current distribution of employees by department, title, and gender?\n","2. How has the workforce size changed over time, by department and overall?\n","3. What is the average tenure of employees across the company and within specific departments or titles?\n","4. What is the gender diversity breakdown within each department and across different job titles?\n","\n","**B. Compensation & Benefits:**\n","\n","5.  What are the average, median, and range of salaries by department, title, and tenure?\n","6.  How have salary trends evolved over time for different roles or employee groups?\n","7.  Are there significant salary differences based on gender for similar roles/tenure? (Identifying potential pay equity issues)\n","8.  What is the average salary increase rate per year, and how does it vary by department or title?\n","\n","**C. Talent Mobility & Turnover:**\n","\n","9.  What is the overall employee turnover rate, and how does it vary by department, manager, or title over time?\n","10. Which departments or managers experience the highest/lowest employee retention rates?\n","11. What is the average duration employees stay in a particular title before promotion or departure?\n","12. What are the common career paths or transitions within the company (e.g., from 'Engineer' to 'Senior Engineer', or internal department transfers)?\n","13. How frequently do employees change departments or titles?\n","\n","**D. Management & Leadership:**\n","\n","14. Which managers have the longest average tenure with their teams?\n","15. How many employees report to each manager over time? (Understanding span of control).\n","16. What is the average salary of managers compared to non-managers?"]},{"cell_type":"markdown","id":"0d06e36c","metadata":{"papermill":{"duration":0.002968,"end_time":"2025-05-21T22:24:58.725897","exception":false,"start_time":"2025-05-21T22:24:58.722929","status":"completed"},"tags":[]},"source":["<a id='data_collection'></a>\n","\n","# <div style=\"background-color:#03002e; padding:18px; border-radius:8px; color:white; text-align:center; font-weight:regular; overflow:hidden\"><strong>Step 2 ‚Ä¢ Data collection</strong></div>\n","\n","This dataset has a rich lineage, originating from academic research and evolving through various formats to its current relational structure:\n","\n","**Original authors**: \n","The foundational dataset was authored by Prof. Dr. Fusheng Wang [üîó](https://www3.cs.stonybrook.edu/~fuswang/) (then a PhD student at the University of California, Los Angeles - UCLA) and his advisor, Prof. Dr. Carlo Zaniolo [üîó](https://web.cs.ucla.edu/~zaniolo/) (UCLA). This work is primarily described in their paper: **Wang, F., & Zaniolo, C. (2004). *Publishing and Querying the Histories of Archived Relational Databases in XML*. [DOI:10.1109/WISE.2003.1254473](http://dx.doi.org/10.1109/WISE.2003.1254473).**\n","\n","**Relational conversion**: It was originally distributed as an `.xml` file. Giuseppe Maxia (known as @datacharmer on GitHub[üîó](https://github.com/datacharmer/) and LinkedIn[üîó](https://www.linkedin.com/in/datacharmer/), as well as here on Kaggle) converted it into its relational form and subsequently distributed it as a `.sql` file, making it accessible for relational database use.\n","\n","**Kaggle upload**: This `.sql` version was then loaded to Kaggle as the ¬´ [Employees Dataset](https://www.kaggle.com/datasets/huzaifamirza/employees-dataset) ¬ª by Mirza Huzaifa[üîó](https://www.linkedin.com/in/mirza-huzaifa-ali-baig-601743223/) on February 5th, 2023.  \n","\n","\n","**Kaggle dataset**: On May 20th, 2025, for convenient access and ease of use in analytical tools, the `.sql` file has been [converted](https://www.kaggle.com/code/isissantoscosta/create-database-from-sql-file-sqlite/) into a single `.db` (SQLite) database file as well as a set of individual `.csv` files by √çsis Santos Costa[üîó](https://www.linkedin.com/in/isis-santos-costa/), and loaded into this Kaggle Dataset: [üéì 365DS Practice Exams ‚Ä¢ People Analytics Dataset](https://www.kaggle.com/datasets/isissantoscosta/365ds-practice-exams-people-analytics-dataset)."]},{"cell_type":"code","execution_count":1,"id":"672ff6aa","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-05-21T22:24:58.734212Z","iopub.status.busy":"2025-05-21T22:24:58.733763Z","iopub.status.idle":"2025-05-21T22:25:00.852581Z","shell.execute_reply":"2025-05-21T22:25:00.851394Z"},"papermill":{"duration":2.125645,"end_time":"2025-05-21T22:25:00.854712","exception":false,"start_time":"2025-05-21T22:24:58.729067","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/365ds-practice-exams-people-analytics-dataset/dept_emp.csv\n","/kaggle/input/365ds-practice-exams-people-analytics-dataset/dept_manager.csv\n","/kaggle/input/365ds-practice-exams-people-analytics-dataset/employees.csv\n","/kaggle/input/365ds-practice-exams-people-analytics-dataset/titles.csv\n","/kaggle/input/365ds-practice-exams-people-analytics-dataset/salaries.csv\n","/kaggle/input/365ds-practice-exams-people-analytics-dataset/employees.db\n","/kaggle/input/365ds-practice-exams-people-analytics-dataset/departments.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"e29772ff","metadata":{"papermill":{"duration":0.003271,"end_time":"2025-05-21T22:25:00.861727","exception":false,"start_time":"2025-05-21T22:25:00.858456","status":"completed"},"tags":[]},"source":["<a id='data_prep'></a>\n","\n","# <div style=\"background-color:#03002e; padding:18px; border-radius:8px; color:white; text-align:center; font-weight:regular; overflow:hidden\"><strong>Step 3 ‚Ä¢ Data prep</strong></div>\n","\n"]},{"cell_type":"markdown","id":"b34d7e6e","metadata":{"papermill":{"duration":0.003113,"end_time":"2025-05-21T22:25:00.868211","exception":false,"start_time":"2025-05-21T22:25:00.865098","status":"completed"},"tags":[]},"source":["## üîé Inspecting the dataset"]},{"cell_type":"code","execution_count":2,"id":"0fc51a0f","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2025-05-21T22:25:00.877016Z","iopub.status.busy":"2025-05-21T22:25:00.876554Z","iopub.status.idle":"2025-05-21T22:25:03.322245Z","shell.execute_reply":"2025-05-21T22:25:03.321015Z"},"papermill":{"duration":2.452375,"end_time":"2025-05-21T22:25:03.324027","exception":false,"start_time":"2025-05-21T22:25:00.871652","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["üîé INSPECTING THE DATASET ##############################################################\n","\n","\n","\n"," TABLES INFO ++++++++++++++++++++++++++++++++++++++\n","\n","\n"," DEPARTMENTS\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9 entries, 0 to 8\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   dept_no    9 non-null      object\n"," 1   dept_name  9 non-null      object\n","dtypes: object(2)\n","memory usage: 276.0+ bytes\n","\n","\n"," DEPT_EMP\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 331603 entries, 0 to 331602\n","Data columns (total 4 columns):\n"," #   Column     Non-Null Count   Dtype \n","---  ------     --------------   ----- \n"," 0   emp_no     331603 non-null  int64 \n"," 1   dept_no    331603 non-null  object\n"," 2   from_date  331603 non-null  object\n"," 3   to_date    331603 non-null  object\n","dtypes: int64(1), object(3)\n","memory usage: 10.1+ MB\n","\n","\n"," DEPT_MANAGER\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 24 entries, 0 to 23\n","Data columns (total 4 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   emp_no     24 non-null     int64 \n"," 1   dept_no    24 non-null     object\n"," 2   from_date  24 non-null     object\n"," 3   to_date    24 non-null     object\n","dtypes: int64(1), object(3)\n","memory usage: 900.0+ bytes\n","\n","\n"," EMPLOYEES\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 300024 entries, 0 to 300023\n","Data columns (total 6 columns):\n"," #   Column      Non-Null Count   Dtype \n","---  ------      --------------   ----- \n"," 0   emp_no      300024 non-null  int64 \n"," 1   birth_date  300024 non-null  object\n"," 2   first_name  300024 non-null  object\n"," 3   last_name   300024 non-null  object\n"," 4   gender      300024 non-null  object\n"," 5   hire_date   300024 non-null  object\n","dtypes: int64(1), object(5)\n","memory usage: 13.7+ MB\n","\n","\n"," SALARIES\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 967330 entries, 0 to 967329\n","Data columns (total 4 columns):\n"," #   Column     Non-Null Count   Dtype \n","---  ------     --------------   ----- \n"," 0   emp_no     967330 non-null  int64 \n"," 1   salary     967330 non-null  int64 \n"," 2   from_date  967330 non-null  object\n"," 3   to_date    967330 non-null  object\n","dtypes: int64(2), object(2)\n","memory usage: 29.5+ MB\n","\n","\n"," TITLES\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 443308 entries, 0 to 443307\n","Data columns (total 4 columns):\n"," #   Column     Non-Null Count   Dtype \n","---  ------     --------------   ----- \n"," 0   emp_no     443308 non-null  int64 \n"," 1   title      443308 non-null  object\n"," 2   from_date  443308 non-null  object\n"," 3   to_date    443308 non-null  object\n","dtypes: int64(1), object(3)\n","memory usage: 13.5+ MB\n","\n","\n","\n"," COLUMN NAMES +++++++++++++++++++++++++++++++++++++\n","\n","\n"," DEPARTMENTS\n","['dept_no', 'dept_name']\n","\n","\n"," DEPT_EMP\n","['emp_no', 'dept_no', 'from_date', 'to_date']\n","\n","\n"," DEPT_MANAGER\n","['emp_no', 'dept_no', 'from_date', 'to_date']\n","\n","\n"," EMPLOYEES\n","['emp_no', 'birth_date', 'first_name', 'last_name', 'gender', 'hire_date']\n","\n","\n"," SALARIES\n","['emp_no', 'salary', 'from_date', 'to_date']\n","\n","\n"," TITLES\n","['emp_no', 'title', 'from_date', 'to_date']\n"]}],"source":["table_names = ['departments', \n","               'dept_emp', \n","               'dept_manager', \n","               'employees', \n","               'salaries', \n","               'titles']\n","\n","dfs = []\n","for table_name in table_names:\n","    df = pd.read_csv('/kaggle/input/365ds-practice-exams-people-analytics-dataset/' + table_name + '.csv')\n","    dfs.append(df)\n","\n","print('üîé INSPECTING THE DATASET ##############################################################')\n","\n","print('\\n\\n\\n TABLES INFO ++++++++++++++++++++++++++++++++++++++')\n","for (table_name, df) in zip(table_names, dfs):\n","    print('\\n\\n', table_name.upper())\n","    df.info()\n","\n","print('\\n\\n\\n COLUMN NAMES +++++++++++++++++++++++++++++++++++++')\n","for (table_name, df) in zip(table_names, dfs):\n","    print('\\n\\n', table_name.upper())\n","    print(list(df.columns))"]},{"cell_type":"markdown","id":"bd044bfe","metadata":{"papermill":{"duration":0.00361,"end_time":"2025-05-21T22:25:03.331574","exception":false,"start_time":"2025-05-21T22:25:03.327964","status":"completed"},"tags":[]},"source":["## üè∑Ô∏è Applying appropriate data types"]},{"cell_type":"code","execution_count":3,"id":"7f45990c","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2025-05-21T22:25:03.340472Z","iopub.status.busy":"2025-05-21T22:25:03.340158Z","iopub.status.idle":"2025-05-21T22:25:05.629109Z","shell.execute_reply":"2025-05-21T22:25:05.628088Z"},"papermill":{"duration":2.295397,"end_time":"2025-05-21T22:25:05.630697","exception":false,"start_time":"2025-05-21T22:25:03.3353","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n"," üè∑Ô∏è APPLYING APPROPRIATE DATA TYPES ###################################################### \n","datetime64[ns] dept_emp from_date\n","datetime64[ns] dept_emp to_date\n","datetime64[ns] dept_manager from_date\n","datetime64[ns] dept_manager to_date\n","datetime64[ns] employees birth_date\n","category employees gender\n","datetime64[ns] employees hire_date\n","datetime64[ns] salaries from_date\n","datetime64[ns] salaries to_date\n","datetime64[ns] titles from_date\n","datetime64[ns] titles to_date\n","\n","\n","\n"," TABLES DESCRIBE ++++++++++++++++++++++++++++++++++\n","\n","\n"," DEPARTMENTS \n","        dept_no  dept_name\n","count        9          9\n","unique       9          9\n","top       d001  Marketing\n","freq         1          1\n","\n","\n"," DEPT_EMP \n","               emp_no                      from_date  \\\n","count  331603.000000                         331603   \n","mean   253332.605025  1993-01-01 23:42:24.762260864   \n","min     10001.000000            1985-01-01 00:00:00   \n","25%     85005.500000            1989-02-25 00:00:00   \n","50%    250001.000000            1993-01-27 00:00:00   \n","75%    424999.500000            1996-11-09 00:00:00   \n","max    499999.000000            2002-08-01 00:00:00   \n","std    161831.919445                            NaN   \n","\n","                             to_date  \n","count                          91479  \n","mean   1997-04-14 03:28:02.235267200  \n","min              1985-02-17 00:00:00  \n","25%              1994-10-14 00:00:00  \n","50%              1998-03-09 00:00:00  \n","75%              2000-06-07 00:00:00  \n","max              2002-08-01 00:00:00  \n","std                              NaN  \n","\n","\n"," DEPT_MANAGER \n","               emp_no            from_date              to_date\n","count      24.000000                   24                   15\n","mean   110780.833333  1989-05-12 01:00:00  1991-12-23 06:24:00\n","min    110022.000000  1985-01-01 00:00:00  1988-09-09 00:00:00\n","25%    110284.250000  1985-01-01 00:00:00  1990-07-27 12:00:00\n","50%    110646.000000  1989-08-26 12:00:00  1991-10-01 00:00:00\n","75%    111199.750000  1992-03-29 18:00:00  1992-08-20 12:00:00\n","max    111939.000000  1996-08-30 00:00:00  1996-08-30 00:00:00\n","std       627.958713                  NaN                  NaN\n","\n","\n"," EMPLOYEES \n","               emp_no                     birth_date  \\\n","count  300024.000000                         300024   \n","mean   253321.763392  1958-07-31 16:12:23.268538560   \n","min     10001.000000            1952-02-01 00:00:00   \n","25%     85006.750000            1955-05-01 00:00:00   \n","50%    249987.500000            1958-08-01 00:00:00   \n","75%    424993.250000            1961-10-28 00:00:00   \n","max    499999.000000            1965-02-01 00:00:00   \n","std    161828.235540                            NaN   \n","\n","                           hire_date  \n","count                         300024  \n","mean   1990-01-28 17:39:00.388768896  \n","min              1985-01-01 00:00:00  \n","25%              1987-02-08 00:00:00  \n","50%              1989-06-20 00:00:00  \n","75%              1992-07-30 00:00:00  \n","max              2000-01-28 00:00:00  \n","std                              NaN  \n","\n","\n"," SALARIES \n","               emp_no         salary                      from_date  \\\n","count  967330.000000  967330.000000                         967330   \n","mean    62483.925957   63761.204329  1996-03-19 20:41:26.047987840   \n","min     10001.000000   38735.000000            1985-01-01 00:00:00   \n","25%     35491.000000   50437.000000            1993-03-04 00:00:00   \n","50%     60924.000000   61070.000000            1996-11-02 00:00:00   \n","75%     86385.000000   74123.000000            1999-09-29 00:00:00   \n","max    201771.000000  158220.000000            2002-08-01 00:00:00   \n","std     34018.647698   16922.546114                            NaN   \n","\n","                             to_date  \n","count                         885695  \n","mean   1996-08-30 01:53:21.806942592  \n","min              1985-03-01 00:00:00  \n","25%              1993-10-12 00:00:00  \n","50%              1997-04-12 00:00:00  \n","75%              2000-01-16 00:00:00  \n","max              2002-08-01 00:00:00  \n","std                              NaN  \n","\n","\n"," TITLES \n","               emp_no                      from_date  \\\n","count  443308.000000                         443308   \n","mean   253075.034430  1994-01-25 01:15:39.377588480   \n","min     10001.000000            1985-01-01 00:00:00   \n","25%     84855.750000            1990-07-19 00:00:00   \n","50%    249847.500000            1994-06-27 00:00:00   \n","75%    424891.250000            1997-10-07 00:00:00   \n","max    499999.000000            2002-08-01 00:00:00   \n","std    161853.292613                            NaN   \n","\n","                             to_date  \n","count                         203184  \n","mean   1997-04-01 10:41:39.078667776  \n","min              1985-03-01 00:00:00  \n","25%              1994-09-24 00:00:00  \n","50%              1997-07-25 00:00:00  \n","75%              2000-02-09 00:00:00  \n","max              2002-08-01 00:00:00  \n","std                              NaN  \n"]}],"source":["# The INFO seen above reveals that the following fields need to be casted to the appropriate type:\n","# Category: ['gender']\n","# Datetime: ['from_date', 'to_date', 'birth_date', 'hire_date']\n","\n","category_cols = ['gender']\n","datetime_cols = ['from_date', 'to_date', 'birth_date', 'hire_date']\n","\n","print('\\n\\n\\n üè∑Ô∏è APPLYING APPROPRIATE DATA TYPES ###################################################### ')\n","for (table_name, df) in zip(table_names, dfs):\n","    \n","    column_names = df.columns\n","    for column_name in column_names:\n","        \n","        if column_name in category_cols:\n","            df[column_name] = df[column_name].astype('category')\n","            print(df[column_name].dtype, table_name, column_name)\n","            \n","        if column_name in datetime_cols:\n","            df[column_name] = df[column_name].replace('9999-01-01', pd.NaT)\n","            df[column_name] = df[column_name].astype('datetime64[ns]')\n","            print(df[column_name].dtype, table_name, column_name)\n","\n","print('\\n\\n\\n TABLES DESCRIBE ++++++++++++++++++++++++++++++++++')\n","for (table_name, df) in zip(table_names, dfs):\n","    print('\\n\\n', table_name.upper(), '\\n', df.describe())"]},{"cell_type":"markdown","id":"3d67a919","metadata":{"papermill":{"duration":0.004078,"end_time":"2025-05-21T22:25:05.639399","exception":false,"start_time":"2025-05-21T22:25:05.635321","status":"completed"},"tags":[]},"source":["<a id='data_analysis_365'></a>\n","\n","# <div style=\"background-color:#03002e; padding:18px; border-radius:8px; color:white; text-align:center; font-weight:regular; overflow:hidden\"><strong>Step 4 ‚Ä¢ Data Analysis | Exam Questions</strong></div>"]},{"cell_type":"markdown","id":"8135ff31","metadata":{"papermill":{"duration":0.003985,"end_time":"2025-05-21T22:25:05.647801","exception":false,"start_time":"2025-05-21T22:25:05.643816","status":"completed"},"tags":[]},"source":["## Exam 2 ‚Ä¢ Question 1\n","Retrieve a list of all employees hired in year 2000, sorted by first name in ascending order.\n","What is the last name of third employee from the obtained input? [^question_note]\n","\n","<br>\n","\n","---  \n","\n","[^question_note] Questions are here paraphrased in a concise manner. For full context and original phrasing, please refer to the exam sponsor [üîó](https://learn.365datascience.com/exams/)."]},{"cell_type":"code","execution_count":4,"id":"2d5dc3ec","metadata":{"execution":{"iopub.execute_input":"2025-05-21T22:25:05.658208Z","iopub.status.busy":"2025-05-21T22:25:05.657856Z","iopub.status.idle":"2025-05-21T22:25:05.68579Z","shell.execute_reply":"2025-05-21T22:25:05.684933Z"},"papermill":{"duration":0.034918,"end_time":"2025-05-21T22:25:05.687246","exception":false,"start_time":"2025-05-21T22:25:05.652328","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'Delgrande'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Getting the employees table\n","df_idx = table_names.index('employees')\n","df = dfs[df_idx]\n","df\n","\n","# Filtering to `hire_date` year = 2000\n","df = df[df['hire_date'].dt.year == 2000]\n","df\n","\n","### Sorting by first name in ascending order\n","df = df.sort_values(by='first_name', ascending=True)\n","df\n","\n","### Getting the last name of the third listed employee\n","ans = df.iloc[3-1]['last_name']\n","ans"]},{"cell_type":"markdown","id":"97fcbd7b","metadata":{"papermill":{"duration":0.004132,"end_time":"2025-05-21T22:25:05.695909","exception":false,"start_time":"2025-05-21T22:25:05.691777","status":"completed"},"tags":[]},"source":["## Exam 2 ‚Ä¢ Question 2\n","Prepare: `department`, `female_avg_salary`, `male_avg_salary`.\n","Compare. [^question_note]\n","\n","<br>\n","\n","---  \n","\n","[^question_note] Questions are here paraphrased in a concise manner. For full context and original phrasing, please refer to the exam sponsor [üîó](https://learn.365datascience.com/exams/)."]},{"cell_type":"code","execution_count":5,"id":"6637c673","metadata":{"execution":{"iopub.execute_input":"2025-05-21T22:25:05.70588Z","iopub.status.busy":"2025-05-21T22:25:05.705442Z","iopub.status.idle":"2025-05-21T22:25:06.600986Z","shell.execute_reply":"2025-05-21T22:25:06.600066Z"},"papermill":{"duration":0.902265,"end_time":"2025-05-21T22:25:06.602476","exception":false,"start_time":"2025-05-21T22:25:05.700211","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>gender</th>\n","      <th>F</th>\n","      <th>M</th>\n","    </tr>\n","    <tr>\n","      <th>dept_name</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Sales</th>\n","      <td>80626.56</td>\n","      <td>80879.76</td>\n","    </tr>\n","    <tr>\n","      <th>Marketing</th>\n","      <td>71464.48</td>\n","      <td>72198.19</td>\n","    </tr>\n","    <tr>\n","      <th>Finance</th>\n","      <td>69914.92</td>\n","      <td>70327.03</td>\n","    </tr>\n","    <tr>\n","      <th>Research</th>\n","      <td>59712.78</td>\n","      <td>59965.77</td>\n","    </tr>\n","    <tr>\n","      <th>Production</th>\n","      <td>59456.00</td>\n","      <td>59596.36</td>\n","    </tr>\n","    <tr>\n","      <th>Development</th>\n","      <td>59391.95</td>\n","      <td>59576.33</td>\n","    </tr>\n","    <tr>\n","      <th>Customer Service</th>\n","      <td>58998.73</td>\n","      <td>58590.99</td>\n","    </tr>\n","    <tr>\n","      <th>Quality Management</th>\n","      <td>57423.31</td>\n","      <td>57206.90</td>\n","    </tr>\n","    <tr>\n","      <th>Human Resources</th>\n","      <td>55596.37</td>\n","      <td>55196.55</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["gender                     F         M\n","dept_name                             \n","Sales               80626.56  80879.76\n","Marketing           71464.48  72198.19\n","Finance             69914.92  70327.03\n","Research            59712.78  59965.77\n","Production          59456.00  59596.36\n","Development         59391.95  59576.33\n","Customer Service    58998.73  58590.99\n","Quality Management  57423.31  57206.90\n","Human Resources     55596.37  55196.55"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# INFO needed:\n","# salaries: `salaries` table\n","# gender: `employees` table\n","# department: `dept_emp` table, `departments` table\n","\n","# Get the salaries table (967330 rows √ó 4 columns)\n","df_idx = table_names.index('salaries')\n","df1 = dfs[df_idx]\n","df1\n","\n","# Get the employees table (300024 rows √ó 6 columns)\n","df_idx = table_names.index('employees')\n","df2 = dfs[df_idx]\n","df2\n","\n","# Join salaries ‚ãà employees\n","df = pd.merge(df1, df2, on='emp_no', how='inner')\n","df\n","\n","# Get the dept_emp table (331603 rows √ó 4 columns)\n","df_idx = table_names.index('dept_emp')\n","df3 = dfs[df_idx]\n","df3\n","\n","# Join df ‚ãà dept_emp\n","df = pd.merge(df, df3, on='emp_no', how='inner', suffixes=('_' + 'salary', '_' + 'dept'))\n","df\n","\n","# Get the departments table (9 rows √ó 2 columns)\n","df_idx = table_names.index('departments')\n","df4 = dfs[df_idx]\n","df4\n","\n","# Join df ‚ãà departments\n","df = pd.merge(df, df4, on='dept_no', how='inner')\n","df\n","\n","# Subset to fields of interest (‚ö†Ô∏è to be reviewed)\n","df = df[['dept_name', 'gender', 'salary']]\n","df\n","\n","# Prepare `dept_name`, `female_avg_salary`, `male_avg_salary`\n","df = df.pivot_table(\n","    index='dept_name',\n","    columns='gender',\n","    values='salary',\n","    aggfunc='mean',\n","    observed=False\n",").round(2)\n","df\n","\n","# Compare\n","df = df.sort_values(by='M', ascending=False)\n","df"]},{"cell_type":"markdown","id":"752a08ab","metadata":{"papermill":{"duration":0.00427,"end_time":"2025-05-21T22:25:06.61143","exception":false,"start_time":"2025-05-21T22:25:06.60716","status":"completed"},"tags":[]},"source":["WIP ‚Ä¢ to be continued (coming soon, in May 2025)"]},{"cell_type":"markdown","id":"305c686d","metadata":{"papermill":{"duration":0.004195,"end_time":"2025-05-21T22:25:06.6202","exception":false,"start_time":"2025-05-21T22:25:06.616005","status":"completed"},"tags":[]},"source":["<a id='data_analysis_extra'></a>\n","\n","# <div style=\"background-color:#03002e; padding:18px; border-radius:8px; color:white; text-align:center; font-weight:regular; overflow:hidden\"><strong>Step 4 ‚Ä¢ Data Analysis | Extra</strong></div>\n","\n","\n","WIP (coming soon, in May 2025)"]},{"cell_type":"markdown","id":"d468a265","metadata":{"papermill":{"duration":0.004264,"end_time":"2025-05-21T22:25:06.628887","exception":false,"start_time":"2025-05-21T22:25:06.624623","status":"completed"},"tags":[]},"source":["<a id='synthesis'></a>\n","\n","# <div style=\"background-color:#03002e; padding:18px; border-radius:8px; color:white; text-align:center; font-weight:regular; overflow:hidden\"><strong>Step 5 ‚Ä¢ Synthesis</strong></div>\n","\n","\n","WIP (coming soon, in May 2025)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7466319,"sourceId":11880127,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":13.733769,"end_time":"2025-05-21T22:25:07.153501","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-21T22:24:53.419732","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}